{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def8f3d7-9af4-4c04-b012-f4849e971872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kadai5\n",
    "# 学習モデルは3NN、バッチ正規化を全結合層1と中間層の間で行う。\n",
    "# 中間層の活性化関数にはシグモイド関数を用いる\n",
    "# また、学習時のパラメータ更新方法は慣性項つきSGDを採用している\n",
    "def mnist_recog(w1, b1, w2, b2, gamma, beta, test_mean, test_var):\n",
    "    #     イプシロンの値\n",
    "    epsilon = 0.001\n",
    "    i = int(input(\"0~60000の整数を入力してください\"))\n",
    "    # 784次元ベクトル\n",
    "    test_data = X[i].reshape(picture_size)\n",
    "#     入力層\n",
    "    input_layer = InputLayer(test_data)\n",
    "#     全結合層1\n",
    "    connection1_layer = Connection1Layer(input_layer.output(), w1, b1)\n",
    "#     正規化\n",
    "    e1 = (gamma / np.sqrt(test_var + epsilon)) * connection1_layer.test_output()\n",
    "    e2 = beta - gamma * test_mean / np.sqrt(test_var + epsilon)\n",
    "    normalized_output = e1 + e2\n",
    "#   中間層\n",
    "    middle_layer = MiddleLayer(normalized_output, sigmoid)\n",
    "#     全結合層2\n",
    "    connection2_layer = Connection2Layer(middle_layer.output(), w2, b2)\n",
    "#     出力層\n",
    "    output_layer = OutputLayer(connection2_layer.test_output(), softmax)\n",
    "    result = np.argmax(output_layer.output())\n",
    "    plt.imshow(X[i], cmap=cm.gray)\n",
    "    plt.show()\n",
    "    print(\"正解は:\"+str(Y[i]))\n",
    "\n",
    "    print(\"予測結果は:\"+str(result))\n",
    "\n",
    "w1 = np.load('/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/w1.npy')\n",
    "b1 = np.load('/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/b1.npy')\n",
    "w2 = np.load('/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/w2.npy')\n",
    "b2 = np.load('/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/b2.npy')\n",
    "gamma = np.load('/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/gamma.npy')\n",
    "beta = np.load('/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/beta.npy')\n",
    "test_mean = np.load('/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/test_mean.npy')\n",
    "test_var = np.load('/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/test_var.npy')\n",
    "print(\"テスト開始します\")\n",
    "mnist_recog(w1, b1, w2, b2, gamma, beta, test_mean, test_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a273a9d-4d33-4f0e-b6f2-5f2193117dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mnistコンテスト\n",
    "# フィルターは3 * 3\n",
    "# シード値を固定する\n",
    "np.random.seed(673)\n",
    "# チャンネル数\n",
    "ch = 1\n",
    "# 畳み込み層フィルタのサイズ\n",
    "R = 3\n",
    "# pooling層フィルタのサイズ\n",
    "R_pool = 2\n",
    "# フィルタの数\n",
    "K = 30\n",
    "# 2つ目のフィルターの数\n",
    "K2 = 60\n",
    "# 畳み込み層のストライド\n",
    "s = 1\n",
    "# pooling層のストライド\n",
    "s_pool = 2\n",
    "# バッチ数\n",
    "batch = 100\n",
    "# 2回目のプーリングが終了した時点でのデータのサイズ\n",
    "d_c = int(28/(2*2))\n",
    "d = K2 * d_c * d_c\n",
    "# 中間層のノード数\n",
    "M = 50\n",
    "# フィルター行列 K , R * R * ch\n",
    "filter_matrix1 =  np.array(np.random.normal(0, 1/np.sqrt(d), (K, R * R * ch)))\n",
    "# フィルター行列2 \n",
    "filter_matrix2 = np.array(np.random.normal(0, 1/np.sqrt(d), (K2, R * R * K)))\n",
    "# 畳み込み層のバイアス項、K次元ベクトル\n",
    "bias_vector1 = np.array(np.random.normal(0, 1/np.sqrt(d), K))\n",
    "# 畳み込み層2のバイアス、K2次元ベクトル\n",
    "bias_vector2 = np.array(np.random.normal(0, 1/np.sqrt(d), K2))\n",
    "# d×M(中間層のノード数)の行列W1\n",
    "W1_matrix = np.array(np.random.normal(0, 1/np.sqrt(d), (d, M)))\n",
    "# M次元ベクトルb1\n",
    "b1_vector = np.array(np.random.normal(0, 1/np.sqrt(d), M))\n",
    "# C×M行列W2\n",
    "W2_matrix = np.array(np.random.normal(0, 1/np.sqrt(M), (M, C)))\n",
    "# C次元ベクトルb2\n",
    "b2_vector = np.array(np.random.normal(0, 1/np.sqrt(M), C))\n",
    "#正規化パラメータの初期値\n",
    "gamma = np.ones(M)\n",
    "beta = np.zeros(M)\n",
    "mean_init = np.zeros(M)\n",
    "var_init = np.zeros(M)\n",
    "\n",
    "\n",
    "def cnn_a2(batch, W_1, b_1, W_2, b_2, gamma_init, beta_init, filter1_init, bias1_init, filter2_init, bias2_init, mean_init, var_init):\n",
    "#      変数を初期化\n",
    "    w1_matrix = W_1\n",
    "    b1_vector = b_1\n",
    "    w2_matrix = W_2\n",
    "    b2_vector = b_2\n",
    "    gamma = gamma_init\n",
    "    beta = beta_init\n",
    "    delta_W1 = np.zeros((d, M))\n",
    "    delta_W2 = np.zeros((M, C))\n",
    "    mean_cross_entropy = 0\n",
    "    mean_mean = np.zeros(M)\n",
    "    mean_var = np.zeros(M)\n",
    "    filter1 = filter1_init\n",
    "    bias1 = bias1_init\n",
    "    filter2 = filter2_init\n",
    "    bias2 = bias2_init\n",
    "    #バッチ正規化前エポックにおけるバッチの平均と分散\n",
    "    mean = mean_init\n",
    "    var = var_init\n",
    "    #慣性項\n",
    "    alpha = 0.9\n",
    "    #学習率\n",
    "    eta = 0.1\n",
    "    #イプシロンの値\n",
    "    epsilon = 0.001\n",
    "    #0~50000までを重複なく取得\n",
    "    sampled_data =  np.random.choice(np.arange(0, 50000), size=(int(50000/batch), batch), replace=False)\n",
    "    i = len(sampled_data)-1\n",
    "#     ここから回す\n",
    "    X_train = X[:, np.newaxis, :, :]\n",
    "    print(X_train)\n",
    "    while(i > 0):\n",
    "        batch_index = sampled_data[i]\n",
    "#     正規化を行う\n",
    "#     この時点ではbatch_vectorsはbatch * ch * dx * dy\n",
    "        batch_vectors = np.array(X_train[batch_index])/255\n",
    "#     正解データ\n",
    "        correct_labels = Y[batch_index]\n",
    "#     one-hot vector表記\n",
    "        one_hot = np.array([np.eye(10)[y] for y in correct_labels]).T\n",
    "#     入力層\n",
    "        input_layer = InputLayer(batch_vectors)\n",
    "#     畳み込み層1\n",
    "        convolution_layer1 = ConvolutionLayer(input_layer.output(), filter1, bias1, batch, R, s)\n",
    "#     畳み込み1の活性化層\n",
    "        activate_layer1 = MiddleLayer(convolution_layer1.output(), relu)\n",
    "#     プーリング層1\n",
    "        pooling_layer1 = PoolingLayer(activate_layer1.output(), batch, R_pool, s_pool)\n",
    "#     畳み込み層2\n",
    "        convolution_layer2 = ConvolutionLayer(pooling_layer1.output(), filter2, bias2, batch, R, s)\n",
    "#     畳み込み層の活性化そう2\n",
    "        activate_layer2 = MiddleLayer(convolution_layer2.output(), relu)\n",
    "#     プーリング層2\n",
    "        pooling_layer2 =  PoolingLayer(activate_layer2.output(), batch, R_pool, s_pool)\n",
    "#     プーリングした多次元配列を行列の形に整形する\n",
    "        preaffine = pooling_layer2.output().reshape(batch, -1).T\n",
    "#     全結合層1\n",
    "        connection1_layer = Connection1Layer(preaffine, w1_matrix, b1_vector)\n",
    "#     バッチ正規化を行う\n",
    "#     平均をとる\n",
    "        row_means = np.mean(connection1_layer.output(), axis=1)\n",
    "        mean_mean += row_means\n",
    "#     分散をとる\n",
    "        row_variances = np.var(connection1_layer.output(), axis=1)\n",
    "        mean_var += row_variances\n",
    "        stdiv = np.sqrt(row_variances + epsilon)\n",
    "        x_hat = (connection1_layer.output() - row_means[:, np.newaxis]) / stdiv[:, np.newaxis]\n",
    "#     正規化する y = γx + β  \n",
    "        normalized_matrix = gamma[:,np.newaxis] * x_hat + beta[:,np.newaxis]\n",
    "#     全結合層1の活性化層\n",
    "        activate_layer3 = MiddleLayer(normalized_matrix, relu)\n",
    "#     全結合層2\n",
    "        connection2_layer = Connection2Layer(activate_layer3.output(), w2_matrix, b2_vector)\n",
    "#     全結合層2の活性化層　ソフトマックス　出力層\n",
    "        output_layer = OutputLayer(connection2_layer.output(), softmax) \n",
    "#     クロスエントロピーソフトマックスの誤差逆伝播\n",
    "        errorback_crossentropy = ErrorBackCrossEntropy(output_layer.output(), one_hot)\n",
    "#     全結合層2の誤差逆伝播\n",
    "        errorback_connect2 = ErrorBackConnect2(activate_layer3.output(), errorback_crossentropy.del_en_x(), w2_matrix)\n",
    "#     全結合層1の活性化層の誤差逆伝播 relu\n",
    "        errorback_relu1 = ErrorBackReLU(normalized_matrix, errorback_connect2.del_en_x())\n",
    "#     バッチ正規化層の誤差逆伝播\n",
    "        errorback_normalize = ErrorBackNormalize(connection1_layer.output(), x_hat, errorback_relu1.del_en_x(), gamma, beta, epsilon, row_means, row_variances, batch)\n",
    "#     全結合層1の誤差逆伝播\n",
    "        errorback_connect1 = ErrorBackConnect1(preaffine, errorback_normalize.del_en_x(), w1_matrix)\n",
    "#     プーリング層2の誤差逆伝播\n",
    "        errorback_pooling2 = ErrorBackPooling(activate_layer2.output(), pooling_layer2.output(), errorback_connect1.del_en_x(), K2, batch, pooling_layer2.max_index(), R_pool, R) \n",
    "#     畳み込み層の活性化層2の誤差逆伝播\n",
    "        errorback_relu2 = ErrorBackReLU(convolution_layer2.output(), errorback_pooling2.del_en_x())\n",
    "#     畳み込み層2の誤差逆伝播\n",
    "        errorback_convolution2 = ErrorBackConvolution(convolution_layer2.rerange(), errorback_relu2.del_en_x(), filter2)\n",
    "#     プーリング層1の誤差逆伝播\n",
    "        errorback_pooling1 = ErrorBackPooling(activate_layer1.output(), pooling_layer1.output(), errorback_convolution2.del_en_x(), K, batch, pooling_layer1.max_index(), R_pool, R)\n",
    "#     畳み込み層1の活性化層1の誤差逆伝播\n",
    "        errorback_relu1 = ErrorBackReLU(convolution_layer1.output(), errorback_pooling1.del_en_x_sub())\n",
    "#     畳み込み層1の誤差逆伝播\n",
    "        errorback_convolution1 = ErrorBackConvolution(convolution_layer1.rerange(), errorback_relu1.del_en_x(), filter1)\n",
    "#     変数の更新\n",
    "        w1_matrix = w1_matrix - eta * errorback_connect1.del_en_w1().T \n",
    "        b1_vector = b1_vector - eta * errorback_connect1.del_en_b1()\n",
    "        w2_matrix = w2_matrix - eta * errorback_connect2.del_en_w2().T \n",
    "        b2_vector = b2_vector - eta * errorback_connect2.del_en_b2()\n",
    "        gamma = gamma - eta * errorback_normalize.del_en_gamma()\n",
    "        beta = beta - eta * errorback_normalize.del_en_beta()\n",
    "        filter1 = filter1 - eta * errorback_convolution1.del_en_w()\n",
    "        bias1 = bias1 - eta * errorback_convolution1.del_en_b()\n",
    "        filter2 = filter2 - eta * errorback_convolution2.del_en_w()\n",
    "        bias2 = bias2 - eta * errorback_convolution2.del_en_b()\n",
    "        i-=1\n",
    "        crossentropy = CrossEntropy(output_layer.output(), one_hot)\n",
    "        mean_cross_entropy += crossentropy.result()\n",
    "        if(i==0):\n",
    "            test_mean = mean_mean / len(sampled_data)\n",
    "            test_var = mean_var / len(sampled_data)\n",
    "            testmean = (test_mean + mean)/2\n",
    "            test_var = (test_var + var)/2\n",
    "            np.save(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/w1\", w1_matrix)\n",
    "            np.save(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/b1\", b1_vector)\n",
    "            np.save(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/w2\", w2_matrix)\n",
    "            np.save(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/b2\", b2_vector)\n",
    "            np.save(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/gamma\", gamma)\n",
    "            np.save(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/beta\", beta)\n",
    "            np.save(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/test_mean\", test_mean)\n",
    "            np.save(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/test_var\", test_var)\n",
    "            np.save(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/filter1\", filter1)\n",
    "            np.save(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/bias1\", bias1)\n",
    "            np.save(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/filter2\", filter2)\n",
    "            np.save(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/bias2\", bias2)\n",
    "            print(\"平均のクロスエントロピー\"+str(mean_cross_entropy/len(sampled_data)))\n",
    "            print(\"正解率:\" + str(calculate_similarity(np.argmax(output_layer.output(), axis=0).tolist(), correct_labels)))\n",
    "            print(\"テスト開始\")\n",
    "            test_matrix = X_train[50000:]\n",
    "            test_vectors = test_matrix\n",
    "            b, k, dx, dy = test_vectors.shape\n",
    "#     正規化\n",
    "            test_vectors = np.array(test_vectors) / 255\n",
    "            answer_labels = Y[50000:]\n",
    "#     入力層\n",
    "            input_layer = InputLayer(test_vectors)\n",
    "#     畳み込み層1\n",
    "            convolution_layer1 = ConvolutionLayer(input_layer.output(), filter1, bias1, b, R, s)\n",
    "#     畳み込み層1の活性化\n",
    "            activate_layer1 = MiddleLayer(convolution_layer1.output(), relu)\n",
    "#     プーリング層1\n",
    "            pooling_layer1 = PoolingLayer(activate_layer1.output(), b, R_pool, s_pool)\n",
    "# 　　　　　　 畳み込み層2\n",
    "            convolution_layer2 = ConvolutionLayer(pooling_layer1.output(), filter2, bias2, b, R, s)\n",
    "#     畳み込み層2の活性化\n",
    "            activate_layer2 = MiddleLayer(convolution_layer2.output(), relu)\n",
    "#     プーリング層2\n",
    "            pooling_layer2 =  PoolingLayer(activate_layer2.output(), b, R_pool, s_pool)\n",
    "#     プーリングした多次元配列を行列の形に整形する\n",
    "            preaffine = pooling_layer2.output().reshape(b, -1).T\n",
    "#     全結合層1\n",
    "            connection1_layer = Connection1Layer(preaffine, w1_matrix, b1_vector)\n",
    "#     正規化層\n",
    "            e1 = (gamma / np.sqrt(test_var + epsilon))[:,np.newaxis] * connection1_layer.output()\n",
    "            e2 = beta - gamma * test_mean / np.sqrt(test_var + epsilon)\n",
    "            normalized_output = e1 + e2[:,np.newaxis]\n",
    "#     中間層\n",
    "            middle_layer = MiddleLayer(normalized_output, relu)\n",
    "#     全結合層2\n",
    "            connection2_layer = Connection2Layer(middle_layer.output(), w2_matrix, b2_vector)\n",
    "#     出力層\n",
    "            output_layer = OutputLayer(connection2_layer.output(), softmax)\n",
    "            print(\"テスト正解率:\" + str(calculate_similarity(np.argmax(output_layer.output(), axis=0).tolist(), answer_labels)))\n",
    "\n",
    "\n",
    "\n",
    "# cnn_a2(batch, W1_matrix, b1_vector, W2_matrix, b2_vector,gamma, beta, filter_matrix1, bias_vector1, filter_matrix2, bias_vector2, mean_init, var_init)\n",
    "j = 10\n",
    "while(j > 0):\n",
    "    w1 = np.load(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/w1.npy\")\n",
    "    b1 = np.load(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/b1.npy\")\n",
    "    w2 = np.load(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/w2.npy\")\n",
    "    b2 = np.load(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/b2.npy\")\n",
    "    gamma = np.load(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/gamma.npy\")\n",
    "    beta = np.load(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/beta.npy\")\n",
    "    filter1 = np.load(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/filter1.npy\")\n",
    "    bias1 = np.load(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/bias1.npy\")\n",
    "    filter2 = np.load(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/filter2.npy\")\n",
    "    bias2 = np.load(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/bias2.npy\")\n",
    "    mean = np.load(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/test_mean.npy\")\n",
    "    var = np.load(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/test_var.npy\")\n",
    "    cnn_a2(100, w1, b1, w2, b2, gamma, beta, filter1, bias1, filter2, bias2, mean, var)\n",
    "    j -= 1\n",
    "    print(\"epoch残り\"+str(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caa5155-e6d6-460d-98a6-65b37a627e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# フィルターは3 * 3\n",
    "# シード値を固定する\n",
    "np.random.seed(673)\n",
    "# チャンネル数\n",
    "ch = 3\n",
    "# 畳み込み層フィルタのサイズ\n",
    "R = 3\n",
    "# pooling層フィルタのサイズ\n",
    "R_pool = 2\n",
    "# フィルタの数\n",
    "K = 30\n",
    "# 2つ目のフィルターの数\n",
    "K2 = 60\n",
    "# 畳み込み層のストライド\n",
    "s = 1\n",
    "# pooling層のストライド\n",
    "s_pool = 2\n",
    "# バッチ数\n",
    "batch = 100\n",
    "# 2回目のプーリングが終了した時点でのデータのサイズ\n",
    "d = 3840\n",
    "# 中間層のノード数\n",
    "M = 50\n",
    "# フィルター行列 K , R * R * ch\n",
    "filter_matrix1 =  np.array(np.random.normal(0, 1/np.sqrt(d), (K, R * R * ch)))\n",
    "# フィルター行列2 \n",
    "filter_matrix2 = np.array(np.random.normal(0, 1/np.sqrt(d), (K2, R * R * K)))\n",
    "# 畳み込み層のバイアス項、K次元ベクトル\n",
    "bias_vector1 = np.array(np.random.normal(0, 1/np.sqrt(d), K))\n",
    "# 畳み込み層2のバイアス、K2次元ベクトル\n",
    "bias_vector2 = np.array(np.random.normal(0, 1/np.sqrt(d), K2))\n",
    "# d×M(中間層のノード数)の行列W1\n",
    "W1_matrix = np.array(np.random.normal(0, 1/np.sqrt(d), (d, M)))\n",
    "# M次元ベクトルb1\n",
    "b1_vector = np.array(np.random.normal(0, 1/np.sqrt(d), M))\n",
    "# C×M行列W2\n",
    "W2_matrix = np.array(np.random.normal(0, 1/np.sqrt(M), (M, C)))\n",
    "# C次元ベクトルb2\n",
    "b2_vector = np.array(np.random.normal(0, 1/np.sqrt(M), C))\n",
    "#正規化パラメータの初期値\n",
    "gamma = np.ones(M)\n",
    "beta = np.zeros(M)\n",
    "\n",
    "\n",
    "def cnn_a2(batch, W_1, b_1, W_2, b_2, gamma_init, beta_init, filter1_init, bias1_init, filter2_init, bias2_init):\n",
    "#      変数を初期化\n",
    "    w1_matrix = W_1\n",
    "    b1_vector = b_1\n",
    "    w2_matrix = W_2\n",
    "    b2_vector = b_2\n",
    "    gamma = gamma_init\n",
    "    beta = beta_init\n",
    "    delta_W1 = np.zeros((d, M))\n",
    "    delta_W2 = np.zeros((M, C))\n",
    "    mean_cross_entropy = 0\n",
    "    mean_mean = np.zeros(M)\n",
    "    mean_var = np.zeros(M)\n",
    "    filter1 = filter1_init\n",
    "    bias1 = bias1_init\n",
    "    filter2 = filter2_init\n",
    "    bias2 = bias2_init\n",
    "    #慣性項\n",
    "    alpha = 0.9\n",
    "    #学習率\n",
    "    eta = 0.05\n",
    "    #イプシロンの値\n",
    "    epsilon = 0.001\n",
    "    #0~50000までを重複なく取得\n",
    "    sampled_data =  np.random.choice(np.arange(0, 50000), size=(int(50000/batch), batch), replace=False)\n",
    "    i = len(sampled_data)-1\n",
    "#     ここから回す\n",
    "    while(i > 0):\n",
    "        batch_index = sampled_data[i]\n",
    "#     正規化を行う\n",
    "#     この時点ではbatch_vectorsはbatch * ch * dx * dy\n",
    "        batch_vectors = np.array(X_color[batch_index])/255\n",
    "#     正解データ\n",
    "        correct_labels = Y_color[batch_index]\n",
    "#     one-hot vector表記\n",
    "        one_hot = np.array([np.eye(10)[y] for y in correct_labels]).T\n",
    "#     入力層\n",
    "        input_layer = InputLayer(batch_vectors)\n",
    "#     畳み込み層1\n",
    "        # print(f'{input_layer.output().shape=}')\n",
    "        convolution_layer1 = ConvolutionLayer(input_layer.output(), filter1, bias1, batch, R, s)\n",
    "#     畳み込み1の活性化層\n",
    "        activate_layer1 = MiddleLayer(convolution_layer1.output(), relu)\n",
    "        # print(f'{activate_layer1.output().shape=}')\n",
    "#     プーリング層1\n",
    "        pooling_layer1 = PoolingLayer(activate_layer1.output(), batch, R_pool, s_pool)\n",
    "        # print(f'{pooling_layer1.output().shape=}')\n",
    "#     畳み込み層2\n",
    "        convolution_layer2 = ConvolutionLayer(pooling_layer1.output(), filter2, bias2, batch, R, s)\n",
    "#     畳み込み層の活性化そう2\n",
    "        activate_layer2 = MiddleLayer(convolution_layer2.output(), relu)\n",
    "        # print(f'{activate_layer2.output().shape=}')\n",
    "#     プーリング層2\n",
    "        pooling_layer2 =  PoolingLayer(activate_layer2.output(), batch, R_pool, s_pool)\n",
    "        # print(f'{pooling_layer2.output().shape=}')\n",
    "        # print(f'{pooling_layer2.max_index().shape=}')\n",
    "#     プーリングした多次元配列を行列の形に整形する\n",
    "        preaffine = pooling_layer2.output().reshape(batch, -1).T\n",
    "        # print(f'{preaffine.shape=}')\n",
    "#     全結合層1\n",
    "        connection1_layer = Connection1Layer(preaffine, w1_matrix, b1_vector)\n",
    "#     バッチ正規化を行う\n",
    "#     平均をとる\n",
    "        row_means = np.mean(connection1_layer.output(), axis=1)\n",
    "        mean_mean += row_means\n",
    "#     分散をとる\n",
    "        row_variances = np.var(connection1_layer.output(), axis=1)\n",
    "        mean_var += row_variances\n",
    "        stdiv = np.sqrt(row_variances + epsilon)\n",
    "        x_hat = (connection1_layer.output() - row_means[:, np.newaxis]) / stdiv[:, np.newaxis]\n",
    "#     正規化する y = γx + β  \n",
    "        normalized_matrix = gamma[:,np.newaxis] * x_hat + beta[:,np.newaxis]\n",
    "#     全結合層1の活性化層\n",
    "        activate_layer3 = MiddleLayer(normalized_matrix, relu)\n",
    "#     全結合層2\n",
    "        connection2_layer = Connection2Layer(activate_layer3.output(), w2_matrix, b2_vector)\n",
    "#     全結合層2の活性化層　ソフトマックス　出力層\n",
    "        output_layer = OutputLayer(connection2_layer.output(), softmax) \n",
    "        # print(f'{output_layer.output().shape=}')\n",
    "#     クロスエントロピーソフトマックスの誤差逆伝播\n",
    "        errorback_crossentropy = ErrorBackCrossEntropy(output_layer.output(), one_hot)\n",
    "#     全結合層2の誤差逆伝播\n",
    "        errorback_connect2 = ErrorBackConnect2(activate_layer3.output(), errorback_crossentropy.output(), w2_matrix)\n",
    "#     全結合層1の活性化層の誤差逆伝播 relu\n",
    "        errorback_relu1 = ErrorBackReLU(normalized_matrix, errorback_connect2.del_en_x())\n",
    "#     バッチ正規化層の誤差逆伝播\n",
    "        errorback_normalize = ErrorBackNormalize(connection1_layer.output(), x_hat, errorback_relu1.del_en_x(), gamma, beta, epsilon, row_means, row_variances, batch)\n",
    "#     全結合層1の誤差逆伝播\n",
    "        errorback_connect1 = ErrorBackConnect1(preaffine, errorback_normalize.del_en_x(), w1_matrix)\n",
    "        # print(f'{errorback_connect1.del_en_x().shape=}')\n",
    "#     プーリング層2の誤差逆伝播\n",
    "        errorback_pooling2 = ErrorBackPooling(activate_layer2.output(), pooling_layer2.output(), errorback_connect1.del_en_x(), K2, batch, pooling_layer2.max_index(), R_pool, R) \n",
    "#     畳み込み層の活性化層2の誤差逆伝播\n",
    "        errorback_relu2 = ErrorBackReLU(convolution_layer2.output(), errorback_pooling2.del_en_x())\n",
    "        # print(f'{errorback_relu2.del_en_x().shape=}')\n",
    "#     畳み込み層2の誤差逆伝播\n",
    "        errorback_convolution2 = ErrorBackConvolution(convolution_layer2.rerange(), errorback_relu2.del_en_x(), filter2)\n",
    "        # print(f'{errorback_convolution2.del_en_x().shape=}')\n",
    "#     プーリング層1の誤差逆伝播\n",
    "        errorback_pooling1 = ErrorBackPooling(activate_layer1.output(), pooling_layer1.output(), \\\n",
    "                                              errorback_convolution2.del_en_x(),\\\n",
    "                                              K, batch, pooling_layer1.max_index(), R_pool, R)\n",
    "        # print(f'{errorback_pooling1.del_en_x_sub().shape=}')\n",
    "#     畳み込み層1の活性化層1の誤差逆伝播\n",
    "        errorback_relu1 = ErrorBackReLU(convolution_layer1.output(), errorback_pooling1.del_en_x_sub())\n",
    "        # print(f'{errorback_relu1.del_en_x().shape=}')\n",
    "#     畳み込み層1の誤差逆伝播\n",
    "        errorback_convolution1 = ErrorBackConvolution(convolution_layer1.rerange(), errorback_relu1.del_en_x(), filter1)\n",
    "        # print(f'{errorback_convolution1.del_en_x().shape=}')\n",
    "#     変数の更新\n",
    "        w1_matrix = w1_matrix - eta * errorback_connect1.del_en_w1().T #+ alpha * delta_W1\n",
    "        b1_vector = b1_vector - eta * errorback_connect1.del_en_b1()\n",
    "        w2_matrix = w2_matrix - eta * errorback_connect2.del_en_w2().T #+ alpha * delta_W2\n",
    "        b2_vector = b2_vector - eta * errorback_connect2.del_en_b2()\n",
    "        gamma = gamma - eta * errorback_normalize.del_en_gamma()\n",
    "        beta = beta - eta * errorback_normalize.del_en_beta()\n",
    "        # delta_W1 = alpha * delta_W1 - eta * errorback_connect1.del_en_w1().T \n",
    "        # delta_W2 = alpha * delta_W2 - eta * errorback_connect2.del_en_w2().T\n",
    "        filter1 = filter1 - eta * errorback_convolution1.del_en_w()\n",
    "        bias1 = bias1 - eta * errorback_convolution1.del_en_b()\n",
    "        filter2 = filter2 - eta * errorback_convolution2.del_en_w()\n",
    "        bias2 = bias2 - eta * errorback_convolution2.del_en_b()\n",
    "        i-=1\n",
    "        crossentropy = CrossEntropy(output_layer.output(), one_hot)\n",
    "        mean_cross_entropy += crossentropy.result()\n",
    "        if(i==0):\n",
    "            test_mean = mean_mean / len(sampled_data)\n",
    "            test_var = mean_var / len(sampled_data)\n",
    "            np.save(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/w1\", w1_matrix)\n",
    "            np.save(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/b1\", b1_vector)\n",
    "            np.save(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/w2\", w2_matrix)\n",
    "            np.save(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/b2\", b2_vector)\n",
    "            np.save(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/gamma\", gamma)\n",
    "            np.save(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/beta\", beta)\n",
    "            np.save(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/test_mean\", test_mean)\n",
    "            np.save(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/test_var\", test_var)\n",
    "            np.save(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/filter1\", filter1)\n",
    "            np.save(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/bias1\", bias1)\n",
    "            np.save(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/filter2\", filter2)\n",
    "            np.save(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/bias2\", bias2)\n",
    "            print(\"平均のクロスエントロピー\"+str(mean_cross_entropy/len(sampled_data)))\n",
    "            print(\"正解率:\" + str(calculate_similarity(np.argmax(output_layer.output(), axis=0).tolist(), correct_labels)))\n",
    "            print(\"テスト開始\")\n",
    "            test_matrix = X_color[50000:]\n",
    "            test_vectors = test_matrix\n",
    "            b, k, dx, dy = test_vectors.shape\n",
    "#     正規化\n",
    "            test_vectors = np.array(test_vectors) / 255\n",
    "            answer_labels = Y_color[50000:]\n",
    "#     入力層\n",
    "            input_layer = InputLayer(test_vectors)\n",
    "#     畳み込み層1\n",
    "            convolution_layer1 = ConvolutionLayer(input_layer.output(), filter1, bias1, b, R, s)\n",
    "#     畳み込み層1の活性化\n",
    "            activate_layer1 = MiddleLayer(convolution_layer1.output(), relu)\n",
    "#     プーリング層1\n",
    "            pooling_layer1 = PoolingLayer(activate_layer1.output(), b, R_pool, s_pool)\n",
    "# 　　　　　　 畳み込み層2\n",
    "            convolution_layer2 = ConvolutionLayer(pooling_layer1.output(), filter2, bias2, b, R, s)\n",
    "#     畳み込み層2の活性化\n",
    "            activate_layer2 = MiddleLayer(convolution_layer2.output(), relu)\n",
    "#     プーリング層2\n",
    "            pooling_layer2 =  PoolingLayer(activate_layer2.output(), b, R_pool, s_pool)\n",
    "#     プーリングした多次元配列を行列の形に整形する\n",
    "            preaffine = pooling_layer2.output().reshape(b, -1).T\n",
    "#     全結合層1\n",
    "            connection1_layer = Connection1Layer(preaffine, w1_matrix, b1_vector)\n",
    "#     正規化層\n",
    "            e1 = (gamma / np.sqrt(test_var + epsilon))[:,np.newaxis] * connection1_layer.output()\n",
    "            e2 = beta - gamma * test_mean / np.sqrt(test_var + epsilon)\n",
    "            normalized_output = e1 + e2[:,np.newaxis]\n",
    "#     中間層\n",
    "            middle_layer = MiddleLayer(normalized_output, relu)\n",
    "#     全結合層2\n",
    "            connection2_layer = Connection2Layer(middle_layer.output(), w2_matrix, b2_vector)\n",
    "#     出力層\n",
    "            output_layer = OutputLayer(connection2_layer.output(), softmax)\n",
    "            print(\"テスト正解率:\" + str(calculate_similarity(np.argmax(output_layer.output(), axis=0).tolist(), answer_labels)))\n",
    "\n",
    "\n",
    "\n",
    "# cnn_a2(batch, W1_matrix, b1_vector, W2_matrix, b2_vector,gamma, beta, filter_matrix1, bias_vector1, filter_matrix2, bias_vector2)\n",
    "j = 50\n",
    "while(j > 0):\n",
    "    w1 = np.load(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/w1.npy\")\n",
    "    b1 = np.load(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/b1.npy\")\n",
    "    w2 = np.load(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/w2.npy\")\n",
    "    b2 = np.load(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/b2.npy\")\n",
    "    gamma = np.load(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/gamma.npy\")\n",
    "    beta = np.load(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/beta.npy\")\n",
    "    filter1 = np.load(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/filter1.npy\")\n",
    "    bias1 = np.load(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/bias1.npy\")\n",
    "    filter2 = np.load(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/filter2.npy\")\n",
    "    bias2 = np.load(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/cnn_params/bias2.npy\")\n",
    "    cnn_a2(100, w1, b1, w2, b2, gamma, beta, filter1, bias1, filter2, bias2)\n",
    "    j -= 1\n",
    "    print(\"epoch残り\"+str(j))\n",
    "    \n",
    "    \n",
    "middle_output = (1 - rho) * connection1_layer.output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff7f90bc-110e-4480-9468-6b73617d9c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 1. 2. 3. 0.]\n",
      " [0. 4. 5. 6. 0.]\n",
      " [0. 7. 8. 9. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# kadai4-3　正規化層の誤差逆伝播クラス\n",
    "class ErrorBackNormalize:\n",
    "    def __init__(self, x, x_hat, del_en_y, gamma, beta, epsilon, mean, var, batch):\n",
    "        self.x = x\n",
    "        self.x_hat = x_hat\n",
    "        self.del_en_y = del_en_y\n",
    "        self.gamma = gamma\n",
    "        self.beta = beta\n",
    "        self.epsilon = epsilon\n",
    "        self.mean = mean\n",
    "        self.var = var\n",
    "        self.batch = batch\n",
    "    def del_en_x_hat(self):\n",
    "        return self.del_en_y * self.gamma[:,np.newaxis]\n",
    "    def del_en_var(self):\n",
    "#         dot = np.dot(self.del_en_x_hat(), (self.x - self.mean[:, np.newaxis]).T)\n",
    "        mult = np.sum(self.del_en_x_hat()*(self.x - self.mean[:, np.newaxis]), axis=1)\n",
    "        return (-1) / 2 * mult *  np.power((self.var + self.epsilon), -1.5 ) \n",
    "    def del_en_mean(self):\n",
    "        e1 = np.sum(self.del_en_x_hat(), axis=1)  * (-1) / np.sqrt(self.var + self.epsilon)\n",
    "        e2 = (-2) * self.del_en_var() * (np.sum(self.x, axis=1)/self.batch - self.mean)\n",
    "        return e1 + e2\n",
    "    def del_en_x(self):\n",
    "        e1 = self.del_en_x_hat() / np.sqrt(self.var + self.epsilon)[:,np.newaxis]\n",
    "        # e2 = np.dot(self.del_en_var(),  2 * (self.x - self.mean[:,np.newaxis]) / self.batch)\n",
    "        e2 = 2 / self.batch * (self.x - self.mean[:,np.newaxis]) * self.del_en_var()[:,np.newaxis]\n",
    "        e3 = self.del_en_mean() / self.batch\n",
    "        return e1 + e2 + e3[:,np.newaxis]\n",
    "    def del_en_gamma(self):\n",
    "#         return np.dot(self.del_en_y, self.x.T)\n",
    "        return np.sum(self.del_en_y * self.x, axis=1)\n",
    "    def del_en_beta(self):\n",
    "        return np.sum(self.del_en_y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c97221-5dba-4fcf-93a3-9df79e42abcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 中間層の逆伝播のクラス\n",
    "# シグモイド関数の逆伝播のクラス\n",
    "class ErrorBackSigmoid:\n",
    "    def __init__(self, y, del_en_y):\n",
    "        self.y = y\n",
    "        self.del_en_y = del_en_y\n",
    "    def del_en_x(self):\n",
    "        new_y = (1 - self.y) * self.y\n",
    "        result = self.del_en_y * new_y\n",
    "        return result\n",
    "    \n",
    "\n",
    "    \n",
    "# dropoutの逆伝播クラス\n",
    "class ErrorBackDropout:\n",
    "    def __init__(self, y, del_en_y):\n",
    "        self.y = y\n",
    "        self.del_en_y = del_en_y\n",
    "    def del_en_x(self):\n",
    "        new_y = np.where(self.y == 0, 0, 1)\n",
    "        result = self.del_en_y * new_y\n",
    "        return result\n",
    "    \n",
    "    \n",
    "# relu関数の逆伝播のクラス\n",
    "class ErrorBackReLU:\n",
    "    def __init__(self, y, del_en_y):\n",
    "        self.y = y\n",
    "        self.del_en_y = del_en_y\n",
    "    def del_en_x(self):\n",
    "        new_y = np.where(self.y > 0, 1, 0)\n",
    "        result = self.del_en_y * new_y\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebad339a-8a44-4897-972f-51850c8669c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.1028355  0.32319785 0.71324856 0.1670102  0.98844242]\n",
      "   [0.76267178 0.87464583 0.31017586 0.3689388  0.18648986]\n",
      "   [0.67636376 0.32426962 0.35151872 0.23574788 0.25382644]\n",
      "   [0.7721921  0.23282726 0.58395781 0.08480852 0.65378878]]\n",
      "\n",
      "  [[0.98591665 0.689069   0.38280698 0.54377466 0.31933048]\n",
      "   [0.66157364 0.68965801 0.8698021  0.00216858 0.40242423]\n",
      "   [0.8932428  0.35150836 0.42598193 0.16432568 0.2192716 ]\n",
      "   [0.46058209 0.15506183 0.14115755 0.56617916 0.15572319]]\n",
      "\n",
      "  [[0.49912119 0.55678119 0.57958779 0.73465517 0.49057835]\n",
      "   [0.13057577 0.59607215 0.78984572 0.52755376 0.10096084]\n",
      "   [0.64987741 0.61786315 0.09926521 0.64880617 0.07295284]\n",
      "   [0.05813394 0.70234085 0.38517469 0.01688556 0.90905829]]]\n",
      "\n",
      "\n",
      " [[[0.13624181 0.60135829 0.38503173 0.42203064 0.22312015]\n",
      "   [0.58655798 0.27825374 0.39116294 0.73531168 0.25858771]\n",
      "   [0.37817507 0.73350351 0.49440443 0.98483296 0.30774896]\n",
      "   [0.17937271 0.36897985 0.55097523 0.91592721 0.11779539]]\n",
      "\n",
      "  [[0.03143304 0.50990735 0.62535544 0.57896649 0.75805533]\n",
      "   [0.23373077 0.39930966 0.93914041 0.8490476  0.18321156]\n",
      "   [0.21422878 0.09825851 0.67160427 0.93659141 0.75233203]\n",
      "   [0.91217204 0.71987306 0.76503043 0.96020089 0.55698709]]\n",
      "\n",
      "  [[0.84536643 0.45878507 0.61139199 0.22279918 0.20069023]\n",
      "   [0.80241934 0.97691227 0.00250077 0.48535466 0.71455853]\n",
      "   [0.2733135  0.58007988 0.25890803 0.69185771 0.04496948]\n",
      "   [0.45848116 0.03841056 0.23046734 0.31755683 0.75545965]]]]\n",
      "[[[[[[1.02835503e-001 7.62671779e-001 6.76363763e-001 7.72192101e-001]\n",
      "     [7.62671779e-001 6.76363763e-001 7.72192101e-001 9.85916646e-001]\n",
      "     [6.76363763e-001 7.72192101e-001 9.85916646e-001 6.61573645e-001]]\n",
      "\n",
      "    [[9.85916646e-001 6.61573645e-001 8.93242797e-001 4.60582087e-001]\n",
      "     [6.61573645e-001 8.93242797e-001 4.60582087e-001 4.99121187e-001]\n",
      "     [8.93242797e-001 4.60582087e-001 4.99121187e-001 1.30575766e-001]]\n",
      "\n",
      "    [[4.99121187e-001 1.30575766e-001 6.49877413e-001 5.81339386e-002]\n",
      "     [1.30575766e-001 6.49877413e-001 5.81339386e-002 1.36241808e-001]\n",
      "     [6.49877413e-001 5.81339386e-002 1.36241808e-001 5.86557978e-001]]]\n",
      "\n",
      "\n",
      "   [[[9.85916646e-001 6.61573645e-001 8.93242797e-001 4.60582087e-001]\n",
      "     [6.61573645e-001 8.93242797e-001 4.60582087e-001 4.99121187e-001]\n",
      "     [8.93242797e-001 4.60582087e-001 4.99121187e-001 1.30575766e-001]]\n",
      "\n",
      "    [[4.99121187e-001 1.30575766e-001 6.49877413e-001 5.81339386e-002]\n",
      "     [1.30575766e-001 6.49877413e-001 5.81339386e-002 1.36241808e-001]\n",
      "     [6.49877413e-001 5.81339386e-002 1.36241808e-001 5.86557978e-001]]\n",
      "\n",
      "    [[1.36241808e-001 5.86557978e-001 3.78175065e-001 1.79372711e-001]\n",
      "     [5.86557978e-001 3.78175065e-001 1.79372711e-001 3.14330351e-002]\n",
      "     [3.78175065e-001 1.79372711e-001 3.14330351e-002 2.33730772e-001]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[1.36241808e-001 5.86557978e-001 3.78175065e-001 1.79372711e-001]\n",
      "     [5.86557978e-001 3.78175065e-001 1.79372711e-001 3.14330351e-002]\n",
      "     [3.78175065e-001 1.79372711e-001 3.14330351e-002 2.33730772e-001]]\n",
      "\n",
      "    [[3.14330351e-002 2.33730772e-001 2.14228775e-001 9.12172045e-001]\n",
      "     [2.33730772e-001 2.14228775e-001 9.12172045e-001 8.45366434e-001]\n",
      "     [2.14228775e-001 9.12172045e-001 8.45366434e-001 8.02419345e-001]]\n",
      "\n",
      "    [[8.45366434e-001 8.02419345e-001 2.73313497e-001 4.58481155e-001]\n",
      "     [8.02419345e-001 2.73313497e-001 4.58481155e-001 0.00000000e+000]\n",
      "     [2.73313497e-001 4.58481155e-001 0.00000000e+000 0.00000000e+000]]]\n",
      "\n",
      "\n",
      "   [[[3.14330351e-002 2.33730772e-001 2.14228775e-001 9.12172045e-001]\n",
      "     [2.33730772e-001 2.14228775e-001 9.12172045e-001 8.45366434e-001]\n",
      "     [2.14228775e-001 9.12172045e-001 8.45366434e-001 8.02419345e-001]]\n",
      "\n",
      "    [[8.45366434e-001 8.02419345e-001 2.73313497e-001 4.58481155e-001]\n",
      "     [8.02419345e-001 2.73313497e-001 4.58481155e-001 0.00000000e+000]\n",
      "     [2.73313497e-001 4.58481155e-001 0.00000000e+000 0.00000000e+000]]\n",
      "\n",
      "    [[0.00000000e+000 0.00000000e+000 2.40461224e-057 6.81669682e-038]\n",
      "     [0.00000000e+000 2.40461224e-057 6.81669682e-038 9.49317068e-259]\n",
      "     [2.40461224e-057 6.81669682e-038 9.49317068e-259 2.90699782e-033]]]]]]\n"
     ]
    }
   ],
   "source": [
    "#4次元対応の全結合のクラス\n",
    "class Affine:\n",
    "    \n",
    "    # インスタンス変数の定義\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W # 重み\n",
    "        self.b = b # バイアス\n",
    "        self.x = None # 入力データ\n",
    "        self.original_x_shape = None # 入力データのサイズ\n",
    "        self.dW = None # 重みに関する勾配\n",
    "        self.db = None # バイアスに関する勾配\n",
    "    \n",
    "    # 順伝播メソッドの定義\n",
    "    def forward(self, x):\n",
    "        # 入力データのサイズを保存\n",
    "        self.original_x_shape = x.shape\n",
    "        \n",
    "        # バッチサイズ行の2次元配列に変形\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        self.x = x\n",
    "        \n",
    "        # 重み付きバイアスの和の計算\n",
    "        out = np.dot(self.x, self.W) + self.b\n",
    "\n",
    "        return out\n",
    "    \n",
    "    # 逆伝播メソッドの定義\n",
    "    def backward(self, dout):\n",
    "        # 勾配を計算\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        \n",
    "        # 入力データのサイズに変形\n",
    "        dx = dx.reshape(*self.original_x_shape)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5332d0ae-936d-4fea-88c7-901e320d0b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[  0   1   2   3   4   5   6   7]\n",
      "   [  8   9  10  11  12  13  14  15]\n",
      "   [ 16  17  18  19  20  21  22  23]\n",
      "   [ 24  25  26  27  28  29  30  31]\n",
      "   [ 32  33  34  35  36  37  38  39]\n",
      "   [ 40  41  42  43  44  45  46  47]\n",
      "   [ 48  49  50  51  52  53  54  55]\n",
      "   [ 56  57  58  59  60  61  62  63]]\n",
      "\n",
      "  [[ 64  65  66  67  68  69  70  71]\n",
      "   [ 72  73  74  75  76  77  78  79]\n",
      "   [ 80  81  82  83  84  85  86  87]\n",
      "   [ 88  89  90  91  92  93  94  95]\n",
      "   [ 96  97  98  99 100 101 102 103]\n",
      "   [104 105 106 107 108 109 110 111]\n",
      "   [112 113 114 115 116 117 118 119]\n",
      "   [120 121 122 123 124 125 126 127]]\n",
      "\n",
      "  [[128 129 130 131 132 133 134 135]\n",
      "   [136 137 138 139 140 141 142 143]\n",
      "   [144 145 146 147 148 149 150 151]\n",
      "   [152 153 154 155 156 157 158 159]\n",
      "   [160 161 162 163 164 165 166 167]\n",
      "   [168 169 170 171 172 173 174 175]\n",
      "   [176 177 178 179 180 181 182 183]\n",
      "   [184 185 186 187 188 189 190 191]]]\n",
      "\n",
      "\n",
      " [[[192 193 194 195 196 197 198 199]\n",
      "   [200 201 202 203 204 205 206 207]\n",
      "   [208 209 210 211 212 213 214 215]\n",
      "   [216 217 218 219 220 221 222 223]\n",
      "   [224 225 226 227 228 229 230 231]\n",
      "   [232 233 234 235 236 237 238 239]\n",
      "   [240 241 242 243 244 245 246 247]\n",
      "   [248 249 250 251 252 253 254 255]]\n",
      "\n",
      "  [[256 257 258 259 260 261 262 263]\n",
      "   [264 265 266 267 268 269 270 271]\n",
      "   [272 273 274 275 276 277 278 279]\n",
      "   [280 281 282 283 284 285 286 287]\n",
      "   [288 289 290 291 292 293 294 295]\n",
      "   [296 297 298 299 300 301 302 303]\n",
      "   [304 305 306 307 308 309 310 311]\n",
      "   [312 313 314 315 316 317 318 319]]\n",
      "\n",
      "  [[320 321 322 323 324 325 326 327]\n",
      "   [328 329 330 331 332 333 334 335]\n",
      "   [336 337 338 339 340 341 342 343]\n",
      "   [344 345 346 347 348 349 350 351]\n",
      "   [352 353 354 355 356 357 358 359]\n",
      "   [360 361 362 363 364 365 366 367]\n",
      "   [368 369 370 371 372 373 374 375]\n",
      "   [376 377 378 379 380 381 382 383]]]]\n",
      "[[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "   18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "   36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "   54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "   72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "   90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      "  108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      "  126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      "  144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      "  162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      "  180 181 182 183 184 185 186 187 188 189 190 191]\n",
      " [192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209\n",
      "  210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227\n",
      "  228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245\n",
      "  246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263\n",
      "  264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281\n",
      "  282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299\n",
      "  300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317\n",
      "  318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335\n",
      "  336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353\n",
      "  354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371\n",
      "  372 373 374 375 376 377 378 379 380 381 382 383]]\n"
     ]
    }
   ],
   "source": [
    "# クロスエントロピーを計算するクラス\n",
    "class CrossEntropy:\n",
    "    def __init__(self, x, onehot):\n",
    "        self.x = x\n",
    "        self.onehot = onehot\n",
    "    def safelog(self):\n",
    "        try:\n",
    "            result = -np.log(self.x)\n",
    "        except RuntimeWarning as e:\n",
    "            result = np.where(self.x <= 0, 1000, -np.log(self.x))\n",
    "        return result\n",
    "    def result(self):\n",
    "        loglist = self.safelog()\n",
    "        crossentropy = np.sum(self.onehot * loglist, axis=0)\n",
    "        batch = loglist.shape[1]\n",
    "        return np.sum(crossentropy) / batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a2e21eca-9167-4488-86f8-7ba34d0d2898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      "  25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48]\n",
      " [49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72\n",
      "  73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96]]\n",
      "[[[[ 1  2  3  4]\n",
      "   [ 5  6  7  8]\n",
      "   [ 9 10 11 12]\n",
      "   [13 14 15 16]]\n",
      "\n",
      "  [[17 18 19 20]\n",
      "   [21 22 23 24]\n",
      "   [25 26 27 28]\n",
      "   [29 30 31 32]]\n",
      "\n",
      "  [[33 34 35 36]\n",
      "   [37 38 39 40]\n",
      "   [41 42 43 44]\n",
      "   [45 46 47 48]]]\n",
      "\n",
      "\n",
      " [[[49 50 51 52]\n",
      "   [53 54 55 56]\n",
      "   [57 58 59 60]\n",
      "   [61 62 63 64]]\n",
      "\n",
      "  [[65 66 67 68]\n",
      "   [69 70 71 72]\n",
      "   [73 74 75 76]\n",
      "   [77 78 79 80]]\n",
      "\n",
      "  [[81 82 83 84]\n",
      "   [85 86 87 88]\n",
      "   [89 90 91 92]\n",
      "   [93 94 95 96]]]]\n"
     ]
    }
   ],
   "source": [
    "# パラメータ\n",
    "batch = 2  # バッチ数\n",
    "K = 3      # K\n",
    "dx = 4     # dx\n",
    "\n",
    "# 2次元の入力配列を作成（仮のデータ）\n",
    "input_array = np.arange(1, batch * K * dx * dx + 1).reshape(batch, K * dx * dx)\n",
    "print(input_array)\n",
    "# 4次元の出力配列を作成\n",
    "output_array = input_array.reshape(batch, K, dx, dx)\n",
    "\n",
    "# 結果を表示\n",
    "print(output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1dc788ae-011e-4130-a87f-82f5cbd146dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[   0    1    2 ...   13   14   15]\n",
      "  [  16   17   18 ...   29   30   31]\n",
      "  [  32   33   34 ...   45   46   47]\n",
      "  ...\n",
      "  [ 208  209  210 ...  221  222  223]\n",
      "  [ 224  225  226 ...  237  238  239]\n",
      "  [ 240  241  242 ...  253  254  255]]\n",
      "\n",
      " [[ 256  257  258 ...  269  270  271]\n",
      "  [ 272  273  274 ...  285  286  287]\n",
      "  [ 288  289  290 ...  301  302  303]\n",
      "  ...\n",
      "  [ 464  465  466 ...  477  478  479]\n",
      "  [ 480  481  482 ...  493  494  495]\n",
      "  [ 496  497  498 ...  509  510  511]]\n",
      "\n",
      " [[ 512  513  514 ...  525  526  527]\n",
      "  [ 528  529  530 ...  541  542  543]\n",
      "  [ 544  545  546 ...  557  558  559]\n",
      "  ...\n",
      "  [ 720  721  722 ...  733  734  735]\n",
      "  [ 736  737  738 ...  749  750  751]\n",
      "  [ 752  753  754 ...  765  766  767]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[6912 6913 6914 ... 6925 6926 6927]\n",
      "  [6928 6929 6930 ... 6941 6942 6943]\n",
      "  [6944 6945 6946 ... 6957 6958 6959]\n",
      "  ...\n",
      "  [7120 7121 7122 ... 7133 7134 7135]\n",
      "  [7136 7137 7138 ... 7149 7150 7151]\n",
      "  [7152 7153 7154 ... 7165 7166 7167]]\n",
      "\n",
      " [[7168 7169 7170 ... 7181 7182 7183]\n",
      "  [7184 7185 7186 ... 7197 7198 7199]\n",
      "  [7200 7201 7202 ... 7213 7214 7215]\n",
      "  ...\n",
      "  [7376 7377 7378 ... 7389 7390 7391]\n",
      "  [7392 7393 7394 ... 7405 7406 7407]\n",
      "  [7408 7409 7410 ... 7421 7422 7423]]\n",
      "\n",
      " [[7424 7425 7426 ... 7437 7438 7439]\n",
      "  [7440 7441 7442 ... 7453 7454 7455]\n",
      "  [7456 7457 7458 ... 7469 7470 7471]\n",
      "  ...\n",
      "  [7632 7633 7634 ... 7645 7646 7647]\n",
      "  [7648 7649 7650 ... 7661 7662 7663]\n",
      "  [7664 7665 7666 ... 7677 7678 7679]]]\n",
      "(100, 30, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "C = np.arange(5*2560).reshape(5, 2560)\n",
    "C_ex = np.array(np.array_split(C, 2560 // 256, axis=1))\n",
    "C_final = C_ex.reshape(10, 5, 16, 16)\n",
    "# print(C)\n",
    "# print(C_ex)\n",
    "# print(C_final)\n",
    "max_values = np.max(np.max(C_final[:, :, ::2, ::2], axis=2), axis=2)\n",
    "# print(max_values)\n",
    "# max_values_reshaped = max_values.reshape(10, 5, 8, 8)\n",
    "# print(max_values_reshaped)\n",
    "\n",
    "\n",
    "\n",
    "# 仮想的なデータを作成 (100サンプル, 30チャネル, 16x16の画像)\n",
    "data = np.arange(100*30*16*16).reshape(100, 30, 16, 16)\n",
    "print(data[0])\n",
    "\n",
    "# プーリング層のサイズとストライドを設定\n",
    "d = 2  # プーリング層のサイズ (2x2)\n",
    "s = 2  # ストライド (2)\n",
    "\n",
    "# Maxプーリングを適用\n",
    "n, c, h, w = data.shape\n",
    "output_h = (h - d) // s + 1\n",
    "output_w = (w - d) // s + 1\n",
    "pooled_data = data[:, :, :output_h * s, :output_w * s].reshape(n, c, output_h, s, output_w, s)\n",
    "pooled_data = pooled_data.max(axis=(3, 5))\n",
    "print(pooled_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e3417576-2693-43fc-994e-db64bcd54957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3, 4, 9)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 与えられたデータ(batch*ch*dx*dy)とパラメータ(R)を定義\n",
    "batch, ch, dx, dy = 100, 3, 4, 4\n",
    "R = 2\n",
    "\n",
    "# データを生成 (仮のデータ)\n",
    "data = np.random.rand(batch, ch, dx, dy)\n",
    "\n",
    "# ストライドと新しい形状を計算\n",
    "stride = data.strides\n",
    "new_shape = (batch, ch, R * R, (dx - R + 1) * (dy - R + 1))\n",
    "\n",
    "# データを新しい形状に変換\n",
    "result = np.lib.stride_tricks.as_strided(data, shape=(batch, ), strides=stride)\n",
    "\n",
    "# 結果を出力\n",
    "print(result.shape)  # (2, 3, 4, 6) 行列の形状\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "1b58cd81-7cc4-49b2-b509-52854ad62045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9 8 9]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 仮のプーリングデータ\n",
    "pooled_data = np.array([[[[1, 2, 3], [4, 5, 6], [7, 8, 9]],\n",
    "                        [[2, 3, 1], [6, 5, 4], [9, 7, 8]]]])\n",
    "\n",
    "# 最大値のインデックスを取得\n",
    "# max_indices = np.argmax(pooled_data, axis=(2,3))\n",
    "pooled_data = pooled_data.max(axis=(1, 2))\n",
    "\n",
    "print(pooled_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa969f82-a569-456a-aed5-d7f257f80c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0  23 212 239  48\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0  51 174 254 254 226\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0  25 203 254 238 240 128\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0  60 254 254 147   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0 107 254 254 168   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0  23 212 254 171  13   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0 174 254 254  78   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0  21  21 213 254 175  16   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0 107 107 255 239  53   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0  59 242 254 254 165   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0 106 254 207 207  18   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0 210 254 165 165   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0  58 240 254  58  58   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0 170 254 208  21   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0  57 240 254 169   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0 103 254 208  21   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0  56 241 254 102   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0 102 254 252  44   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0 162 254 102   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]\n",
      "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "     0   0   0   0   0   0   0   0   0   0   0]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#ファイルの読み込み\n",
    "with open(\"le4MNIST_X (1).txt\", \"r\") as file:\n",
    "    file_contents = file.read().splitlines()\n",
    "\n",
    "data_list = []\n",
    "for item in file_contents:\n",
    "    numbers = [int(num) for num in item.split()]\n",
    "    reshaped_data = np.array(numbers, dtype=int).reshape(1, 28, 28)\n",
    "    data_list.append(reshaped_data)\n",
    "final_data = np.array(data_list)\n",
    "print(final_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2b5517-e972-4157-a0fc-79374c2b3322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mnistコンテスト本番ファイル（訓練用）\n",
    "#畳み込み→活性化→プーリング→バッチ正規化→活性化→全結合→ソフトマックス\n",
    "#畳み込み層のフィルタサイズは3*3、ストライドは1\n",
    "#活性化関数には全てReLUを用いる\n",
    "#プーリングはフィルタサイズ2*2、ストライドは2\n",
    "\n",
    "np.random.seed(673)\n",
    "#チャンネル数\n",
    "ch = 1\n",
    "#畳み込み層のフィルタサイズ\n",
    "R = 3\n",
    "#プーリング層のフィルタのサイズ\n",
    "R_pool = 2\n",
    "#フィルタの数\n",
    "K = 30\n",
    "#畳み込み層のストライド\n",
    "s = 1\n",
    "#プーリング層のストライド\n",
    "s_pool = 2\n",
    "#バッチ数\n",
    "batch = 100\n",
    "#2回目のプーリングが終了した時点でのデータサイズ\n",
    "d = K * 14 * 14\n",
    "#クラス数\n",
    "C = 10\n",
    "#フィルター行列\n",
    "filter_matrix = np.array(np.random.normal(0, 1/np.sqrt(d), (K, R*R*ch)))\n",
    "#バイアス項\n",
    "bias_vector = np.array(np.random.normal(0, 1/np.sqrt(d), K))\n",
    "#全結合層の行列\n",
    "W_matrix = np.array(np.random.normal(0, 1/np.sqrt(d), (d, C)))\n",
    "#全結合層のベクトル\n",
    "b_vector = np.array(np.random.normal(0, 1/np.sqrt(d), C))\n",
    "#正規化パラメータの初期値\n",
    "gamma_init = np.ones(d)\n",
    "beta_init = np.zeros(d)\n",
    "mean_init = np.zeros(d)\n",
    "var_init = np.zeros(d)\n",
    "\n",
    "def mnistcontest_train(batch, W_init, b_init, gamma_init, beta_init, filter_init, bias_init, mean_init, var_init):\n",
    "    #変数を初期化\n",
    "    W = W_init\n",
    "    b = b_init\n",
    "    gamma = gamma_init\n",
    "    beta = beta_init\n",
    "    mean_cross_entropy = 0\n",
    "    mean_mean = np.zeros(d)\n",
    "    mean_var = np.zeros(d)\n",
    "    filter_matrix = filter_init\n",
    "    bias = bias_init\n",
    "    #バッチ正規化前エポックにおけるバッチの平均と分散\n",
    "    mean = mean_init\n",
    "    var = var_init\n",
    "    #学習率\n",
    "    eta = 0.08\n",
    "    #イプシロンの値\n",
    "    epsilon = 1.0e-10\n",
    "    #0~50000までを重複なく取得\n",
    "    sampled_data =  np.random.choice(np.arange(0, 50000), size=(int(50000/batch), batch), replace=False)\n",
    "    i = len(sampled_data)-1\n",
    "    X_train = X[:, np.newaxis, :, :]\n",
    "    while(i > 0):\n",
    "        batch_index = sampled_data[i] \n",
    "        #正規化\n",
    "        batch_matrix = np.array(X_train[batch_index])/255 \n",
    "        #正解データ\n",
    "        correct_labels = Y[batch_index] \n",
    "        #one-hot\n",
    "        one_hot = np.array([np.eye(10)[y] for y in correct_labels]).T\n",
    "        #入力\n",
    "        input_layer = InputLayer(batch_matrix)\n",
    "        #畳み込み\n",
    "        convolution_layer = Convolution(input_layer.output(), filter_matrix, bias, batch, R, s)\n",
    "        #活性化1\n",
    "        activate_layer1 = MiddleLayer(convolution_layer.output(), relu)\n",
    "        #プーリング\n",
    "        pooling_layer = PoolingLayer(activate_layer1.output(), batch, R_pool, s_pool)\n",
    "        #プーリングした多次元配列を行列の形に整形\n",
    "        preaffine = pooling_layer.output().reshape(batch, -1).T\n",
    "        #バッチ正規化\n",
    "        row_means = np.mean(preaffine, axis=1)\n",
    "        mean_mean += row_means\n",
    "        row_variances = np.var(preaffine, axis=1)\n",
    "        mean_var += row_variances\n",
    "        stdiv = np.sqrt(row_variances + epsilon)\n",
    "        x_hat = (preaffine - row_means[:, np.newaxis]) / stdiv[:, np.newaxis]\n",
    "        normalized_matrix = gamma[:,np.newaxis] * x_hat + beta[:,np.newaxis]\n",
    "        #活性化2\n",
    "        activate_layer2 = MiddleLayer(normalized_matrix, relu)\n",
    "        #全結合\n",
    "        connection_layer = ConnectionLayer(activate_layer2.output(), W, b)\n",
    "        #ソフトマックス\n",
    "        output_layer = OutputLayer(connection_layer.output(), softmax) \n",
    "        #クロスエントロピー誤差伝播\n",
    "        errorback_crossentropy = ErrorBackCrossEntropy(output_layer.output(), one_hot)\n",
    "        #全結合層の逆伝播\n",
    "        errorback_connect = ErrorBackConnect(activate_layer2.output(), errorback_crossentropy.del_en_x(), W)\n",
    "        #活性化2の誤差逆伝播\n",
    "        errorback_relu2 = ErrorBackReLU(normalized_matrix, errorback_connect.del_en_x())\n",
    "        #バッチ正規化層の誤差逆伝播\n",
    "        errorback_normalize = ErrorBackNormalize(preaffine, x_hat, errorback_relu2.del_en_x(), \n",
    "                                                 gamma, beta, epsilon, row_means, row_variances, batch)\n",
    "        #プーリングの誤差逆伝播\n",
    "        errorback_pooling = ErrorBackPooling(activate_layer1.output(), pooling_layer.output(), errorback_normalize.del_en_x(), \n",
    "                                             K, batch, pooling_layer.max_index(), R_pool, R) \n",
    "        #活性化層1の誤差逆伝播\n",
    "        errorback_relu1 = ErrorBackReLU(convolution_layer.output(), errorback_pooling.del_en_x())\n",
    "        #畳み込み層の誤差逆伝播\n",
    "        errorback_convolution = ErrorBackConvolution(convolution_layer.rerange(), errorback_relu1.del_en_x(), filter_matrix)\n",
    "        #変数を更新\n",
    "        W = W - eta * errorback_connect.del_en_w().T\n",
    "        b = b - eta * errorback_connect.del_en_b()\n",
    "        gamma = gamma - eta * errorback_normalize.del_en_gamma()\n",
    "        beta = beta - eta * errorback_normalize.del_en_beta()\n",
    "        filter_matrix = filter_matrix - eta * errorback_convolution.del_en_w()\n",
    "        bias = bias - eta * errorback_convolution.del_en_b()\n",
    "        i -= 1\n",
    "        crossentropy = CrossEntropy(output_layer.output(), one_hot)\n",
    "        mean_cross_entropy += crossentropy.result()\n",
    "        # print(crossentropy.result())\n",
    "        if(i==0):\n",
    "            test_mean = mean_mean / len(sampled_data)\n",
    "            test_var = mean_var / len(sampled_data)\n",
    "            # test_mean = (test_mean + mean)/2\n",
    "            # test_var = (test_var + var)/2\n",
    "            np.save(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/mnist_test/W\", W)\n",
    "            np.save(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/mnist_test/b\", b)\n",
    "            np.save(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/mnist_test/gamma\", gamma)\n",
    "            np.save(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/mnist_test/beta\", beta)\n",
    "            np.save(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/mnist_test/test_mean\", test_mean)\n",
    "            np.save(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/mnist_test/test_var\", test_var)\n",
    "            np.save(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/mnist_test/filter_matrix\", filter_matrix)\n",
    "            np.save(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/mnist_test/bias\", bias)\n",
    "            print(\"平均のクロスエントロピー\"+str(mean_cross_entropy/len(sampled_data)))\n",
    "            print(\"正解率:\" + str(calculate_similarity(np.argmax(output_layer.output(), axis=0).tolist(), correct_labels)))\n",
    "            print(\"テスト開始\")\n",
    "            test_matrix = X_train[50000:]\n",
    "            testbatch, k, dx, dy = test_matrix.shape\n",
    "            #正規化\n",
    "            test_matrix = np.array(test_matrix) / 255\n",
    "            answer_labels = Y[50000:]\n",
    "            #入力層\n",
    "            test_input_layer = InputLayer(test_matrix)\n",
    "            #畳み込み\n",
    "            test_convolution_layer = ConvolutionLayer(test_input_layer.output(), filter_matrix, bias, testbatch, R, s)\n",
    "            #活性化1\n",
    "            test_activate_layer1 = MiddleLayer(test_convolution_layer.output(), relu)\n",
    "            #プーリング\n",
    "            test_pooling_layer = PoolingLayer(test_activate_layer1.output(), testbatch, R_pool, s_pool)\n",
    "            #行列に整形、正規化\n",
    "            test_preaffine = test_pooling_layer.output().reshape(testbatch, -1).T\n",
    "            e1 = (gamma / np.sqrt(test_var + epsilon))[:,np.newaxis] * test_preaffine\n",
    "            e2 = beta - gamma * test_mean / np.sqrt(test_var + epsilon)\n",
    "            normalized_output = e1 + e2[:,np.newaxis]\n",
    "            #活性化2\n",
    "            test_activate_layer2 = MiddleLayer(normalized_output, relu)\n",
    "            #全結合\n",
    "            test_connection_layer = ConnectionLayer(test_activate_layer2.output(), W, b)\n",
    "            #ソフトマックス\n",
    "            output_layer_test = OutputLayer(test_connection_layer.output(), softmax)\n",
    "            print(\"テスト正解率:\" + str(calculate_similarity(np.argmax(output_layer_test.output(), axis=0).tolist(), answer_labels)))\n",
    "            \n",
    "\n",
    "            \n",
    "mnistcontest_train(100, W_matrix, b_vector, gamma_init, beta_init, filter_matrix, bias_vector, mean_init, var_init)\n",
    "# j = 10\n",
    "# while(j > 0):\n",
    "#     W = np.load(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/mnist_test/W.npy\")\n",
    "#     b = np.load(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/mnist_test/b.npy\")\n",
    "#     gamma = np.load(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/mnist_test/gamma.npy\")\n",
    "#     beta = np.load(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/mnist_test/beta.npy\")\n",
    "#     filter_init = np.load(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/mnist_test/filter_matrix.npy\")\n",
    "#     bias = np.load(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/mnist_test/bias.npy\")\n",
    "#     mean = np.load(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/mnist_test/test_mean.npy\")\n",
    "#     var = np.load(\"/Users/mst923/OneDrive - Kyoto University/3年後期/計算機科学実験4/画像処理/mnist_test/test_var.npy\")\n",
    "#     mnistcontest_train(100, W, b, gamma, beta, filter_init, bias, mean, var)\n",
    "#     j -= 1\n",
    "#     print(\"epoch残り\"+str(j))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
